>数据预处理（Preprocessing），旨在产生高质量的数据达到质量标准
>用到的库：pandas，numpy
# 1 需要处理的数据
## 1.1 空缺值
- 人工填写空缺值
- 全局常量替换空缺值
- 使用与给定元组属同一类的所有样本的属性的中心度量填充
- 使用最可能的值填充缺失值
## 1.2 噪声数据
- 噪声数据就是一个测量变量中的随机错误或偏差，包括错误的值或偏离期望的孤立点值
- 噪声数据是无意义的数据，真实世界当中的噪声数据是永远存在的，但是在数据存储过程当中需要去消除这些噪声数据
## 1.3 部分非数值数据
- 有些非数值数据可以转换为1或者0来代表是或否，这样使得数据可以被计算等
# 2 数据清洗实操
## 2.1 语法例子
单纯为了展示语法的演示例子，整体不构成可以运行的文件
```Python
import pandas as pd

#读取csv文件，可以用可选参数sep='\t'指定分隔符为制表符
df = pd.read_csv('chronic_kidney_disease.csv')

#head(n)读取文件前n行，head()默认读5行，若是在notebook中则不需要print，直接df.head()即可
#print(df.head())

#index索引（iloc即integer location），这里是索引并展示编号为1，5，27，58的行
#双层中括号，因为这个函数接收的是一个列表，内层中括号表示创建并传入列表
#同理，在notebook中不需要print
print(df.iloc[[1,5,27,58]])

#查看数据列属性
print(df.columns)

#info()方法用于打印数据集的一些摘要信息，verbose参数控制输出的详细程度，当设置为None时，它将按照默认设置显示摘要信息
#即显示所有列的数据类型，每列的非空值数量以及总体内存使用情况
print(df.info(verbose=None))

#删除表中的某一行或者某一列方法是使用drop，它不改变原有的dataframe中的数据，而是可选择性的返回另一个dataframe来存放删除后的数据
#删除了名为bp的列，axis=1表示删除列
df = df.drop('bp', axis=1)
print(df.info())

"age"和"bp"存在缺失值，对于缺失bp的情况，我们可以丢弃该样本行，等价于保留bp为非空的样本
df = df[df["bp"].notnull()]

#对于缺失age的情况，我们可以用比如18进行填充
#注意数据类型，比如标签下数据为数字的，不可用字符串填充
#字符串可以这样填充：df['some_string'].fillna("unsigned", inplace=True)
df.fillna({'age': 18}, inplace=True)
print(df.info())

#分列
'''
#可以将某列转化为多级分类，并移除原有列
#比如某个样本的"category_name"为"Kids/Toys/Dolls & Accessories"
#可以将其分为"Kids"，"Toys"以及"Dolls & Accessories"并移除原有列

#确认类目数的最大值，可以用'/'的数目+1来判断
category_num = df['category_name'].str.count('/') + 1
min_category_num = category_num.min()
max_category_num = category_num.max()
print(f'{min_category_num}, {max_category_num}')
df[[f'category_name_{i+1}' for i in range(max_category_num)]] = df['category_name'].str.split('/', expand=True)
df.head()

#丢弃原有 category_name 列
#所有商品都有三级类目，这里对所有样本都仅保留三级类目，舍弃过于细的类目分类
df.drop(['category_name', 'category_name_4', 'category_name_5'], axis=1, inplace=True)
df.head()
'''

#分箱
'''
#新增列 "price_level"，根据 "price" 将商品三等分为高、中、低三个档次
#按price三等分
df['price_level'] = pd.qcut(df["price"], 3)

#统计每个价格档次中的商品数，确认基本符合三等分
df.groupby('price_level').count()
'''

#信息抽取
'''
#新增列"has_offer"，如果样本的"description"包含"discount"或"offer"或"sale"，则赋值1，否则为0
df['has_offer'] = df['item_description'].astype(str).apply(lambda x: 1 if 'offer' in x or 'discount' in x or 'sale' in x else 0) df[df['has_offer'] == 1].head()
'''

#保存文件，index=位置的参数指定是否要包含DataFrame的行索引（index）到CSV文件中
df.to_csv("train_cleaned.csv", index = False)
```
## 2.2 Notebook处理数据实战
- 部分数据如下
![](chronic_kidney_disease.csv慢性肾病数据集.png)
```Python
import pandas as pd
#读取csv文件
df = pd.read_csv('work/chronic_kidney_disease.csv')

#将真假类型的列转换为数值数据
bool_columns = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'class']
for col in bool_columns:
    df[col] = df[col].map({'normal': 1, 'abnormal': 0, 'yes': 1, 'no': 0, "present" : 1,"notpresent" : 0, "good" : 1,"poor" : 0, "ckd" : 1, 'notckd' : 0})
df.head()
```
![](转化非数值数据.png)
```Python
#处理数值型空缺值
#age,bp,sg,al,su,bgr,bu,sc,sod,pot,hemo,pcv,wbcc,rbcc用中位数填充
columns_to_fill = ['age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wbcc', 'rbcc']
for col in columns_to_fill:
    median = df[col].median()
    df[col].fillna(median, inplace=True)
df.info()
```
![](中位数填充部分数值数据.png)
```Python
#处理布尔型空缺值
#获取布尔型数据列的列名
bool_columns = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane']

#使用前后值进行填充
for col in bool_columns:
	#fillna是补充缺失值的方法；当使用ffill和bfill这两个方法时，DataFrame 中的缺失值会被按照列顺序逐个填充，首先向前填充，然后向后填充
    df[col] = df[col].fillna(method='ffill').fillna(method='bfill')
df.info()
```
![](空缺值处理完毕.png)
```Python
#处理离群异常值
#定义阈值
threshold = 3
#计算均值和标准差
mean = df.mean()
std = df.std()
#计算Z分数
z_scores = (df - mean) / std
#根据阈值判断离群值
outliers = (z_scores.abs() > threshold).any(axis=1)
#剔除离群值
df = df[~outliers]

#数据可视化图表的绘制，也可以用df.describe()看单纯的数值分析（如平均数等）
df.hist(figsize=(10, 10))
```
![](数据可视化.png)
```Python
#另存为chronic_kidney_disease_cleaned.csv文件
df.to_csv("chronic_kidney_disease_cleaned.csv", index = False)
```
# 3 清洗后的数据分析
- 我们需要分析class对应的值（是否慢性肾病）与其他所有列的值的相关联性，即找出一个或多个与慢性肾病高度相关的指标
```Python
#分析清洗后的数据
df = pd.read_csv('chronic_kidney_disease_cleaned.csv')

#计算相关系数
correlation = df.corr()['class'].sort_values(ascending=False)

#打印与 'class' 列相关性最高的指标
print("与 'class' 列相关性最高的指标:")
print(correlation)

#找出相关系数大于等于阈值的指标（例如，0.5）
threshold = 0.5
highly_correlated_features = correlation[correlation.abs() >= threshold].index.tolist()

print("\n与 'class' 列相关性大于等于 %.2f 的指标:" % threshold)
print(highly_correlated_features)
```
![](相关性分析.png)