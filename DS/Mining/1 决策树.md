# 1.1 决策树简介
- 机器学习中，决策树（Decision Tree）是一个预测模型，他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。数据挖掘中决策树是一种经常要用到的技术，可以用于分析数据，同样也可以用来作预测
# 1.2 应用案例
## 1.2.1 案例描述
- 该项目中，提供了在泰坦尼克号上乘客的具体数据以及他们是否在那次灾难中存活的信息。根据训练数据构建模型来预测此乘客是否能在灾难中存活，本次案例使用的方法 决策树来达到以上预测目的，数据集如下
```
train.csv: 训练数据集，包含特征信息和存活与否信息
test.csv: 测试数据集，只包含特征信息
```
## 1.2.2 分析方法
- 探索性数据分析（Exploratory Data Analysis，EDA）主要的工作是：对数据进行清洗，对数据进行描述（描述统计量，图表），查看数据的分布，比较数据之间的关系，培养对数据的直觉，对数据进行总结等
## 1.2.3 训练集的分析
```Python
import pandas as pd
#读取训练集信息
titan = pd.read_csv("/home/aistudio/data/data74/train.csv")
#查看数据基本信息
titan.info()
#891个样本数据，12列数据，个别列数据存在缺省情况
```
![](mining1.png)
```Python
#预览数据
titan.head()
```
![](mining2.png)
- Survived 是目标变量，即需要预测的变量
![](mining3.png)
- 其他则为乘客相关的数据特征
![](mining4.png)
```Python
#简单分析一下训练集
titan.describe()
```
![](mining5.png)
## 1.2.4 特征寻找
- 特征工程即提取有用的特征、处理缺省值和将特征调整为需要的形式
- `scikit-learn`是基于Python的机器学习工具，是简单高效的数据挖掘和数据分析工具，可以在[官方文档](https://scikit-learn.org/stable/user_guide.html)，[中文文档](https://www.scikitlearn.com.cn/)处进行学习
- `one-hot`编码是一种将分类变量转换为二进制列的方法
![](mining6.png)
```Python
#特征值
x = titan[['Pclass', 'Age', 'Sex']].copy()
#目标值
y = titan['Survived'].copy()

#age缺省值处理，这里用均值填充
fill_value = round(x['Age'].mean(),0)
x['Age'].fillna(fill_value, inplace=True)

#分割训练集与验证集
from sklearn.model_selection import train_test_split
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.25)

#sex为string类型，需要用one_hot编码进行处理
from sklearn.feature_extraction import DictVectorizer
#DictVectorizer(sparse=False)会返回一个one-hot编码矩阵
dict = DictVectorizer(sparse=False)

#orient='records'将数据按每条记录转换成字典格式，字典特征抽取分类string数据
x_train_dict = x_train.to_dict(orient='records')
x_val_dict = x_val.to_dict(orient='records')
x_train_dict[:5]
```
![](mining7.png)
```Python
#转换成字典后的训练集特征值
x_train = dict.fit_transform(x_train_dict)
print(dict.get_feature_names())
x_train[:5]
```
![](mining8.png)
```Python
x_val = dict.transform(x_val_dict)
x_val[:5]
```
![](mining9.png)
## 1.2.5 建模
- 构建决策树
- 查看预测率
```Python
from sklearn.tree import DecisionTreeClassifier

#运行决策树算法
tree = DecisionTreeClassifier()
#分类特征值都是转化为字典形的数据
tree.fit(x_train, y_train)
print('验证集的准确率为：', tree.score(x_val, y_val))

#验证集的准确率为：0.7757847533632287
```
## 1.2.6 导出决策树
- 下载`pydotplus`库
```Python
from sklearn.tree import export_graphviz
import graphviz
import pydotplus
export_graphviz(tree, out_file=r"./decision_tree.dot",
                    feature_names=['年龄', '等级', '女性', '男性'])

with open("./decision_tree.dot") as f: 
    dot_graph = f.read() 

pydot_graph = pydotplus.graph_from_dot_data(dot_graph)
#生成本地图片
pydot_graph.write_png('./tree.png')
#在notebook中查看图片
graphviz.Source(dot_graph)
```
## 1.2.7 若使用测试集
- 上述均为只使用训练集的情况
- 测试集通常也会存在数据问题，一般可将训练级与测试集合并做数据清洗
```Python
#读取两个数据集，路径自己按需求改
test_df = pd.read_csv("/home/aistudio/data/data74/test.csv")
train_df = pd.read_csv("/home/aistudio/data/data74/train.csv")

#合并训练集和测试集
titanic = train_df.append(test_df, ignore_index=True)

#创建索引，后期用于分开数据集
train_idx = len(train_df)
test_idx = len(titanic) - len(test_df)
titanic.info()
```
![](mining10.png)
```Python
#尝试用分组中位数对年龄做填充
grouped = titanic.groupby(['Sex','Pclass'])  
grouped["Age"].median()
```
![](mining11.png)
```Python
titanic["Age"] = grouped["Age"].apply(lambda x: x.fillna(x.median()))
#查看处理后的情况
titanic.info()
print("---"*30)
titanic["Age"]
```
![](mining12.png)
```Python
#使用索引分割训练集与测试集
train = titanic.iloc[ :train_idx]
test = titanic.iloc[test_idx: ]
```
- 接下来和上述步骤一致，使用测试集进行处理
```Python
#特征值
x = train[['Pclass', 'Age', 'Sex']]

#目标值
y = train['Survived']

#使用测试集
x_test = test[['Pclass', 'Age', 'Sex']]

#one_hot编码进行处理，DictVectorizer(sparse=False)会返回一个one-hot编码矩阵
dict = DictVectorizer(sparse=False)  

#orient='records'将数据按每条记录转换成字典格式，字典特征抽取分类string数据
x_train_dict = x.to_dict(orient='records') 
x_test_dict = x_test.to_dict(orient='records')
x_train = dict.fit_transform(x_train_dict)
x_test = dict.transform(x_test_dict)

#运行决策树算法
tree = DecisionTreeClassifier()
tree.fit(x_train, y)
y_test = tree.predict(x_test)

#预测存活率
y_test
```
![](mining13.png)